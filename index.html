<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Lu Sheng · 盛律 </title> <meta name="author" content="Lu Sheng"> <meta name="description" content="Lu Sheng (盛律), Associated Professor @ Beihang University. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://lucassheng.github.io/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%6C%73%68%65%6E%67@%62%75%61%61.%65%64%75.%63%6E" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=_8lB7xcAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/LucasSheng" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://twitter.com/SHENGLui1989" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> <a href="https://dblp.org/pid/132/1772.html" title="DBLP" rel="external nofollow noopener" target="_blank"><i class="ai ai-dblp"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Lu Sheng · 盛律 </h1> <p class="desc"><a href="https://soft.buaa.edu.cn/" rel="external nofollow noopener" target="_blank">School of Software, Beihang University</a></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic_v2-480.webp 480w,/assets/img/prof_pic_v2-800.webp 800w,/assets/img/prof_pic_v2-1400.webp 1400w," sizes="(min-width: 800px) 231.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/prof_pic_v2.png?be20de7bbd1110e19837c71841d6de15" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic_v2.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>I am the Associate Professor at the <a href="http://soft.buaa.edu.cn/" rel="external nofollow noopener" target="_blank">School of Software, Beihang University (BUAA)</a>, China. I am also working closely with <a href="https://www.shlab.org.cn/" rel="external nofollow noopener" target="_blank">Shanghai AI Laboratory</a>.</p> <p>Before I joined BUAA in 2019, I was a postdoctoral researcher (2017-2019) in <a href="https://mmlab.ie.cuhk.edu.hk/" rel="external nofollow noopener" target="_blank">MMLab@CUHK</a>, working with <a href="http://www.ee.cuhk.edu.hk/~xgwang/" rel="external nofollow noopener" target="_blank">Prof. Xiaogang Wang</a>. I received my Ph.D. from <a href="http://www.ee.cuhk.edu.hk/en-gb/" rel="external nofollow noopener" target="_blank">Department of Electronic Engineering</a> at <a href="https://www.cuhk.edu.hk/english/index.html" rel="external nofollow noopener" target="_blank">the Chinese University of Hong Kong (CUHK)</a>, advised by <a href="http://www.ee.cuhk.edu.hk/~knngan/" rel="external nofollow noopener" target="_blank">Prof. King Ngi Ngan</a> (IEEE Life Fellow).</p> <p>My research interests include 3D computer vision and embodied AI. <strong>My current research lies in developing generalizable models for understanding, interacting with and synthesizing 3D visual world.</strong></p> <hr> <p><i class="fa-solid fa-thumbtack" style="color:#b71c1c"></i><b style="color:#b71c1c"> To Prospective Students:</b> I am actively looking for highly-motivated students targeted to Master or Ph.D. degree, as well as undergraduate-level research assistants. Please <a href="mailto:lsheng@buaa.edu.cn">drop me an email</a> with your resume if you are interested in my research.</p> <hr> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Sep 14, 2024</th> <td> I will serve as Area Chair of <a href="https://cvpr.thecvf.com/Conferences/2025" rel="external nofollow noopener" target="_blank">CVPR 2025</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 24, 2024</th> <td> SketchSampler++ (the extension of the previous ECCV 2022 paper <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136610457.pdf" rel="external nofollow noopener" target="_blank">SketchSampler</a>) is accepted at IEEE T-PAMI! Congratulations to all co-authors！ </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 15, 2024</th> <td> <a href="https://github.com/Sense-GVT/Fast-BEV?tab=readme-ov-file" rel="external nofollow noopener" target="_blank">Fast-BEV</a> is finally accepted at <a href="https://ieeexplore.ieee.org/abstract/document/10557672" rel="external nofollow noopener" target="_blank">IEEE T-PAMI</a>! Congratulations to all co-authors！ </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 27, 2024</th> <td> <a href="https://iranqin.github.io/MP5.github.io/" rel="external nofollow noopener" target="_blank">MP5</a> and <a href="https://huanngzh.github.io/EpiDiff/" rel="external nofollow noopener" target="_blank">EpiDiff</a> has been accepted at <a href="https://cvpr.thecvf.com/" rel="external nofollow noopener" target="_blank">CVPR 2024</a>! Please check out the demos in their webpages! </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 17, 2024</th> <td> I will serve as Area Chair of <a href="https://eccv.ecva.net/" rel="external nofollow noopener" target="_blank">ECCV 2024</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 16, 2024</th> <td> Our work <a href="https://openlamm.github.io/paper_list/Octavius" rel="external nofollow noopener" target="_blank">Octavius</a> has been accepted at ICLR 2024! It is one of the first mixture-of-experts (MoE) papers about MLLMs. All <a href="https://github.com/OpenGVLab/LAMM" rel="external nofollow noopener" target="_blank">data and code</a> are now open-sourced, stay tuned for updated! </td> </tr> <tr> <th scope="row" style="width: 20%">Dec 19, 2023</th> <td> Two papers are accepted at <a href="https://aaai.org/aaai-conference/" rel="external nofollow noopener" target="_blank">AAAI 2024</a>! </td> </tr> <tr> <th scope="row" style="width: 20%">Dec 15, 2023</th> <td> I will serve as Area Chair of <a href="https://cvpr.thecvf.com/" rel="external nofollow noopener" target="_blank">CVPR 2024</a> and <a href="https://2024.acmmm.org/" rel="external nofollow noopener" target="_blank">ACM Multimedia 2024</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Dec 01, 2023</th> <td> We have released <a href="https://openlamm.github.io/" rel="external nofollow noopener" target="_blank">LAMM</a>, an open-source project for Multi-Modal Large language Models (MLLMs) and Applications as AI agents. Welcome to join us! </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 01, 2023</th> <td> One paper is accepted at <a href="https://nips.cc/" rel="external nofollow noopener" target="_blank">NeurIPS 2023</a>, the Dataset and Benchmark Track. </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">Preprint</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/neurips24_o3d-480.webp 480w,/assets/img/publication_preview/neurips24_o3d-800.webp 800w,/assets/img/publication_preview/neurips24_o3d-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/neurips24_o3d.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="neurips24_o3d.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="neurips24_o3d" class="col-sm-8"> <div class="title">Ouroboros3D: Image-to-3D Generation via 3D-aware Recursive Diffusion</div> <div class="author"> Hao Wen#, Zehuan Huang# , Yaohui Wang, Xinyuan Chen, <a href="https://mmlab.siat.ac.cn/yuqiao" rel="external nofollow noopener" target="_blank">Yu Qiao</a>, and <em>Lu Sheng*</em> </div> <div class="periodical"> <em>CoRR</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2406.03184" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/Costwen/Ouroboros3D" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://costwen.github.io/Ouroboros3D/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">Preprint</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/acmmm_p2w-480.webp 480w,/assets/img/publication_preview/acmmm_p2w-800.webp 800w,/assets/img/publication_preview/acmmm_p2w-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/acmmm_p2w.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="acmmm_p2w.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="acmmm24_p2w" class="col-sm-8"> <div class="title">From Parts to Whole: A Unified Reference Framework for Controllable Human Image Generation</div> <div class="author"> Zehuan Huang#, Hongxin Fan# , Lipeng Wang#, and <em>Lu Sheng*</em> </div> <div class="periodical"> <em>CoRR</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2404.15267" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/huanngzh/Parts2Whole" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://huanngzh.github.io/Parts2Whole/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">Preprint</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/eccv24_minedreamer-480.webp 480w,/assets/img/publication_preview/eccv24_minedreamer-800.webp 800w,/assets/img/publication_preview/eccv24_minedreamer-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/eccv24_minedreamer.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="eccv24_minedreamer.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="DBLP:journals/corr/abs-2403-12037" class="col-sm-8"> <div class="title">MineDreamer: Learning to Follow Instructions via Chain-of-Imagination for Simulated-World Control</div> <div class="author"> <a href="https://github.com/Zhoues" rel="external nofollow noopener" target="_blank">Enshen Zhou</a>, Yiran Qin, <a href="https://scholar.google.com.hk/citations?user=ngPR1dIAAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Zhenfei Yin</a>, Yuzhou Huang , <a href="http://www.zhangruimao.site/" rel="external nofollow noopener" target="_blank">Ruimao Zhang</a>, <em>Lu Sheng</em>, <a href="https://mmlab.siat.ac.cn/yuqiao" rel="external nofollow noopener" target="_blank">Yu Qiao</a>, and <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a> </div> <div class="periodical"> <em>CoRR</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2403.12037" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/Zhoues/MineDreamer" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://sites.google.com/view/minedreamer/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">Preprint</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/eccv24_ch3ef-480.webp 480w,/assets/img/publication_preview/eccv24_ch3ef-800.webp 800w,/assets/img/publication_preview/eccv24_ch3ef-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/eccv24_ch3ef.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="eccv24_ch3ef.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="DBLP:journals/corr/abs-2403-17830" class="col-sm-8"> <div class="title">Assessment of Multimodal Large Language Models in Alignment with Human Values</div> <div class="author"> Zhelun Shi , Zhipin Wang, Hongxing Fan , Zaibin Zhang, Lijun Li , Yongting Zhang, <a href="https://scholar.google.com.hk/citations?user=ngPR1dIAAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Zhenfei Yin</a>, <em>Lu Sheng</em>, <a href="https://mmlab.siat.ac.cn/yuqiao" rel="external nofollow noopener" target="_blank">Yu Qiao</a>, and <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a> </div> <div class="periodical"> <em>CoRR</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2403.17830" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://openlamm.github.io/ch3ef/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">Preprint</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/eccv24_rh20tp-480.webp 480w,/assets/img/publication_preview/eccv24_rh20tp-800.webp 800w,/assets/img/publication_preview/eccv24_rh20tp-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/eccv24_rh20tp.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="eccv24_rh20tp.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="DBLP:journals/corr/abs-2403-19622" class="col-sm-8"> <div class="title">RH20T-P: A Primitive-Level Robotic Dataset Towards Composable Generalization Agents</div> <div class="author"> Zeren Chen, Zhelun Shi , Xiaoya Lu, Lehan He, Sucheng Qian, <a href="https://fang-haoshu.github.io/" rel="external nofollow noopener" target="_blank">Haoshu Fang</a>, <a href="https://scholar.google.com.hk/citations?user=ngPR1dIAAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Zhenfei Yin</a>, <a href="https://wlouyang.github.io/" rel="external nofollow noopener" target="_blank">Wanli Ouyang</a>, <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a>, <a href="https://mmlab.siat.ac.cn/yuqiao" rel="external nofollow noopener" target="_blank">Yu Qiao</a>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Cewu Lu, Lu Sheng' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">2 more authors</span> </div> <div class="periodical"> <em>CoRR</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2403.19622" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://sites.google.com/view/rh20t-primitive/main" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" rel="external nofollow noopener" target="_blank">IEEE T-PAMI</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/pami24_fast-bev++-480.webp 480w,/assets/img/publication_preview/pami24_fast-bev++-800.webp 800w,/assets/img/publication_preview/pami24_fast-bev++-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/pami24_fast-bev++.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="pami24_fast-bev++.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="pami24_fastbev" class="col-sm-8"> <div class="title">Fast-BEV: A Fast and Strong Bird’s-Eye View Perception Baseline</div> <div class="author"> Yangguang Li, Bin Huang, Zeren Chen, Yufeng Cui, Feng Liang, Mingzhu Shen , Fenggang Liu, Enze Xie, <em>Lu Sheng*</em>, <a href="https://wlouyang.github.io/" rel="external nofollow noopener" target="_blank">Wanli Ouyang</a>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Jing Shao' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">1 more author</span> </div> <div class="periodical"> <em>IEEE Trans. Pattern Anal. Mach. Intell.</em>, early access , 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2301.12511" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/Sense-GVT/Fast-BEV?tab=readme-ov-file" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" rel="external nofollow noopener" target="_blank">IEEE T-PAMI</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/pami24_sketchsampler++-480.webp 480w,/assets/img/publication_preview/pami24_sketchsampler++-800.webp 800w,/assets/img/publication_preview/pami24_sketchsampler++-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/pami24_sketchsampler++.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="pami24_sketchsampler++.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="pami24_fastbew" class="col-sm-8"> <div class="title">3D Reconstruction from a Single Sketch via View-dependent Depth Sampling</div> <div class="author"> Chenjian Gao# , Xilin Wang#, <a href="https://yuqian1023.github.io" rel="external nofollow noopener" target="_blank">Qian Yu*</a>, <em>Lu Sheng</em>, <a href="https://hellojing89.github.io/" rel="external nofollow noopener" target="_blank">Jing Zhang</a>, Xiaoguang Han, Yi-Zhe Song, and <a href="https://www.cs.hku.hk/people/academic-staff/dongxu" rel="external nofollow noopener" target="_blank">Dong Xu</a> </div> <div class="periodical"> <em>IEEE Trans. Pattern Anal. Mach. Intell.</em>, early access , 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2301.12511" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/Sense-GVT/Fast-BEV?tab=readme-ov-file" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr24_epidiff-480.webp 480w,/assets/img/publication_preview/cvpr24_epidiff-800.webp 800w,/assets/img/publication_preview/cvpr24_epidiff-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/cvpr24_epidiff.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr24_epidiff.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="DBLP:journals/corr/abs-2312-06725" class="col-sm-8"> <div class="title">EpiDiff: Enhancing Multi-View Synthesis via Localized Epipolar-Constrained Diffusion</div> <div class="author"> Zehuan Huang#, Hao Wen#, Junting Dong# , Yaohui Wang, Yangguang Li, Xinyuan Chen, Yan-Pei Cao, Ding Liang, <a href="https://mmlab.siat.ac.cn/yuqiao" rel="external nofollow noopener" target="_blank">Yu Qiao</a>, <a href="https://daibo.info/" rel="external nofollow noopener" target="_blank">Bo Dai*</a>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Lu Sheng*' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">1 more author</span> </div> <div class="periodical"> <em>In IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2312.06725" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Huang_EpiDiff_Enhancing_Multi-View_Synthesis_via_Localized_Epipolar-Constrained_Diffusion_CVPR_2024_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/huanngzh/EpiDiff" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://huanngzh.github.io/EpiDiff/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr24_mp5-480.webp 480w,/assets/img/publication_preview/cvpr24_mp5-800.webp 800w,/assets/img/publication_preview/cvpr24_mp5-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/cvpr24_mp5.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr24_mp5.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="DBLP:journals/corr/abs-2312-07472" class="col-sm-8"> <div class="title">MP5: A Multi-modal Open-ended Embodied System in Minecraft via Active Perception</div> <div class="author"> Yiran Qin#, <a href="https://github.com/Zhoues" rel="external nofollow noopener" target="_blank">Enshen Zhou#</a> , Qichang Liu#, <a href="https://scholar.google.com.hk/citations?user=ngPR1dIAAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Zhenfei Yin</a>, <em>Lu Sheng*</em> , <a href="http://www.zhangruimao.site/" rel="external nofollow noopener" target="_blank">Ruimao Zhang*</a>, <a href="https://mmlab.siat.ac.cn/yuqiao" rel="external nofollow noopener" target="_blank">Yu Qiao</a>, and <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a> </div> <div class="periodical"> <em>In IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2312.07472" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Qin_MP5_A_Multi-modal_Open-ended_Embodied_System_in_Minecraft_via_Active_CVPR_2024_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/IranQin/MP5" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://iranqin.github.io/MP5.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ICLR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/iclr24_octavius-480.webp 480w,/assets/img/publication_preview/iclr24_octavius-800.webp 800w,/assets/img/publication_preview/iclr24_octavius-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/iclr24_octavius.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="iclr24_octavius.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="chen2023octavius" class="col-sm-8"> <div class="title">Octavius: Mitigating Task Interference in MLLMs via LoRA-MoE</div> <div class="author"> Zeren Chen# , Ziqin Wang# , Zhen Wang , Huayang Liu, <a href="https://scholar.google.com.hk/citations?user=ngPR1dIAAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Zhenfei Yin</a> , Si Liu, <em>Lu Sheng*</em>, <a href="https://wlouyang.github.io/" rel="external nofollow noopener" target="_blank">Wanli Ouyang</a>, <a href="https://mmlab.siat.ac.cn/yuqiao" rel="external nofollow noopener" target="_blank">Yu Qiao</a>, and <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao*</a> </div> <div class="periodical"> <em>In International Conference on Learning Representations</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2311.02684" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://openreview.net/pdf?id=rTDyN8yajn" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/OpenGVLab/LAMM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://openlamm.github.io/paper_list/Octavius" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">NeurIPS</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/neurips23_lamm-480.webp 480w,/assets/img/publication_preview/neurips23_lamm-800.webp 800w,/assets/img/publication_preview/neurips23_lamm-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/neurips23_lamm.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="neurips23_lamm.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="DBLP:conf/nips/YinWCSLLH0S0SO23" class="col-sm-8"> <div class="title">LAMM: Language-Assisted Multi-Modal Instruction-Tuning Dataset, Framework, and Benchmark</div> <div class="author"> <a href="https://scholar.google.com.hk/citations?user=ngPR1dIAAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Zhenfei Yin#</a> , Jiong Wang#, Jianjian Cao#, Zhelun Shi# , Dingning Liu, Mukai Li, Xiaoshui Huang , Zhiyong Wang, <em>Lu Sheng</em>, Lei Bai*, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Jing Shao*, Wanli Ouyang' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">2 more authors</span> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2306.06687" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="http://papers.nips.cc/paper_files/paper/2023/hash/548a41b9cac6f50dccf7e63e9e1b1b9b-Abstract-Datasets_and_Benchmarks.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://www.youtube.com/watch?v=M7XlIe8hhPk" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://openlamm.github.io/paper_list/LAMM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr23_siamese_detr-480.webp 480w,/assets/img/publication_preview/cvpr23_siamese_detr-800.webp 800w,/assets/img/publication_preview/cvpr23_siamese_detr-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/cvpr23_siamese_detr.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr23_siamese_detr.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="DBLP:conf/cvpr/ChenHLTWSLS23" class="col-sm-8"> <div class="title">Siamese DETR</div> <div class="author"> Zeren Chen#, Gengshi Huang#, Wei Li, Jianing Teng , Kun Wang, <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a>, <a href="https://www.mmlab-ntu.com/person/ccloy/" rel="external nofollow noopener" target="_blank">Chen Change Loy</a>, and <em>Lu Sheng*</em> </div> <div class="periodical"> <em>In IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Siamese_DETR_CVPR_2023_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/Zx55/SiameseDETR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr23_vlsat-480.webp 480w,/assets/img/publication_preview/cvpr23_vlsat-800.webp 800w,/assets/img/publication_preview/cvpr23_vlsat-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/cvpr23_vlsat.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr23_vlsat.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="DBLP:conf/cvpr/WangCZ0TS23" class="col-sm-8"> <div class="title">VL-SAT: Visual-Linguistic Semantics Assisted Training for 3D Semantic Scene Graph Prediction in Point Cloud</div> <div class="author"> Ziqin Wang, Bowen Cheng, Lichen Zhao, <a href="https://www.cs.hku.hk/people/academic-staff/dongxu" rel="external nofollow noopener" target="_blank">Dong Xu</a>, <a href="http://www.ytangecust.com/index.html" rel="external nofollow noopener" target="_blank">Yang Tang*</a>, and <em>Lu Sheng*</em> </div> <div class="periodical"> <em>In IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (<b style="color:#b71c1c">Highlight Poster</b>) , 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_VL-SAT_Visual-Linguistic_Semantics_Assisted_Training_for_3D_Semantic_Scene_Graph_CVPR_2023_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/wz7in/CVPR2023-VLSAT" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr22_3djcg-480.webp 480w,/assets/img/publication_preview/cvpr22_3djcg-800.webp 800w,/assets/img/publication_preview/cvpr22_3djcg-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/cvpr22_3djcg.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr22_3djcg.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="DBLP:conf/cvpr/CaiZZSX22" class="col-sm-8"> <div class="title">3DJCG: A Unified Framework for Joint Dense Captioning and Visual Grounding on 3D Point Clouds</div> <div class="author"> Daigang Cai, Lichen Zhao, <a href="https://hellojing89.github.io/" rel="external nofollow noopener" target="_blank">Jing Zhang*</a>, <em>Lu Sheng</em>, and <a href="https://www.cs.hku.hk/people/academic-staff/dongxu" rel="external nofollow noopener" target="_blank">Dong Xu</a> </div> <div class="periodical"> <em>In IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (<b style="color:#b71c1c">Oral Presentation</b>) , 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_3DJCG_A_Unified_Framework_for_Joint_Dense_Captioning_and_Visual_CVPR_2022_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/zlccccc/3DVL_Codebase" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">AAAI</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/aaai22_danceformer-480.webp 480w,/assets/img/publication_preview/aaai22_danceformer-800.webp 800w,/assets/img/publication_preview/aaai22_danceformer-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/aaai22_danceformer.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="aaai22_danceformer.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="DBLP:conf/aaai/LiZZS22" class="col-sm-8"> <div class="title">DanceFormer: Music Conditioned 3D Dance Generation with Parametric Motion Transformer</div> <div class="author"> Buyu Li, Yongchi Zhao, Zhelun Shi, and <em>Lu Sheng*</em> </div> <div class="periodical"> <em>In Thirty-Sixth AAAI Conference on Artificial Intelligence</em> , 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20014" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/libuyu/PhantomDanceDataset" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr21_forgerynet-480.webp 480w,/assets/img/publication_preview/cvpr21_forgerynet-800.webp 800w,/assets/img/publication_preview/cvpr21_forgerynet-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/cvpr21_forgerynet.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr21_forgerynet.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="DBLP:conf/cvpr/HeGCZYSSS021" class="col-sm-8"> <div class="title">ForgeryNet: A Versatile Benchmark for Comprehensive Forgery Analysis</div> <div class="author"> Yinan He#, Bei Gan#, Siyu Chen# , Yichun Zhou# , Guojun Yin, Luchuan Song, <em>Lu Sheng</em>, <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao*</a> , and <a href="https://liuziwei7.github.io/" rel="external nofollow noopener" target="_blank">Ziwei Liu</a> </div> <div class="periodical"> <em>In IEEE Conference on Computer Vision and Pattern Recognition</em> (<b style="color:#b71c1c">Oral Presentation</b>) , 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/He_ForgeryNet_A_Versatile_Benchmark_for_Comprehensive_Forgery_Analysis_CVPR_2021_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/yinanhe/forgerynet" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://yinanhe.github.io/projects/forgerynet.html#" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=_8lB7xcAAAAJ&amp;citation_for_view=_8lB7xcAAAAJ:4fKUyHm3Qg0C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-130-4285F4?logo=googlescholar&amp;labelColor=beige" alt="130 Google Scholar citations"> </a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr21_brnet-480.webp 480w,/assets/img/publication_preview/cvpr21_brnet-800.webp 800w,/assets/img/publication_preview/cvpr21_brnet-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/cvpr21_brnet.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr21_brnet.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="DBLP:conf/cvpr/ChengSSY021" class="col-sm-8"> <div class="title">Back-Tracing Representative Points for Voting-Based 3D Object Detection in Point Clouds</div> <div class="author"> Bowen Cheng, <em>Lu Sheng*</em>, Shaoshuai Shi, Ming Yang, and <a href="https://www.cs.hku.hk/people/academic-staff/dongxu" rel="external nofollow noopener" target="_blank">Dong Xu</a> </div> <div class="periodical"> <em>In IEEE Conference on Computer Vision and Pattern Recognition</em> , 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Cheng_Back-Tracing_Representative_Points_for_Voting-Based_3D_Object_Detection_in_Point_CVPR_2021_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/cheng052/BRNet" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ICCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/iccv21_3dvg-480.webp 480w,/assets/img/publication_preview/iccv21_3dvg-800.webp 800w,/assets/img/publication_preview/iccv21_3dvg-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/iccv21_3dvg.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="iccv21_3dvg.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="DBLP:conf/iccv/ZhaoCS021" class="col-sm-8"> <div class="title">3DVG-Transformer: Relation Modeling for Visual Grounding on Point Clouds</div> <div class="author"> Lichen Zhao, Daigang Cai, <em>Lu Sheng*</em>, and <a href="https://www.cs.hku.hk/people/academic-staff/dongxu" rel="external nofollow noopener" target="_blank">Dong Xu</a> </div> <div class="periodical"> <em>In IEEE/CVF International Conference on Computer Vision</em> (<b style="color:#b71c1c">1st place at 3D Object Localization Challenge at the CVPR 2021, 1st Workshop on Language for 3D Scenes</b>) , 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_3DVG-Transformer_Relation_Modeling_for_Visual_Grounding_on_Point_Clouds_ICCV_2021_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/zlccccc/3DVG-Transformer" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=_8lB7xcAAAAJ&amp;citation_for_view=_8lB7xcAAAAJ:LPZeul_q3PIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-120-4285F4?logo=googlescholar&amp;labelColor=beige" alt="120 Google Scholar citations"> </a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ACM MM</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/mm21_votehmr-480.webp 480w,/assets/img/publication_preview/mm21_votehmr-800.webp 800w,/assets/img/publication_preview/mm21_votehmr-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/mm21_votehmr.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mm21_votehmr.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="DBLP:conf/mm/LiuRS21" class="col-sm-8"> <div class="title">VoteHMR: Occlusion-Aware Voting Network for Robust 3D Human Mesh Recovery from Partial Point Clouds</div> <div class="author"> Guanze Liu, Yu Rong, and <em>Lu Sheng*</em> </div> <div class="periodical"> <em>In Proceedings of the 29th ACM International Conference on Multimedia</em> (<b style="color:#b71c1c">Oral Presentation</b>) , 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/https://arxiv.org/abs/2110.08729" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://dl.acm.org/doi/abs/10.1145/3474085.3475309" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/hanabi7/VoteHMR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">IJCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ijcv20_highquality-480.webp 480w,/assets/img/publication_preview/ijcv20_highquality-800.webp 800w,/assets/img/publication_preview/ijcv20_highquality-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/ijcv20_highquality.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ijcv20_highquality.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="DBLP:journals/ijcv/ShengPGSL20" class="col-sm-8"> <div class="title">High-Quality Video Generation from Static Structural Annotations</div> <div class="author"> <em>Lu Sheng#*</em>, Junting Pan#, Jiaming Guo, <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a>, and <a href="https://www.mmlab-ntu.com/person/ccloy/" rel="external nofollow noopener" target="_blank">Chen Change Loy</a> </div> <div class="periodical"> <em>Int. J. Comput. Vis.</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="https://link.springer.com/article/10.1007/s11263-020-01334-x" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/junting/seg2vid" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">AAAI</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/aaai20_msn-480.webp 480w,/assets/img/publication_preview/aaai20_msn-800.webp 800w,/assets/img/publication_preview/aaai20_msn-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/aaai20_msn.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="aaai20_msn.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="DBLP:conf/aaai/LiuSYS020" class="col-sm-8"> <div class="title">Morphing and Sampling Network for Dense Point Cloud Completion</div> <div class="author"> Minghua Liu, <em>Lu Sheng</em>, Sheng Yang, <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a>, and Shi-Min Hu </div> <div class="periodical"> <em>In The Thirty-Fourth AAAI Conference on Artificial Intelligence</em> , 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="https://cseweb.ucsd.edu//%C2%A0mil070/projects/AAAI2020/paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/Colin97/MSN-Point-Cloud-Completion" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=_8lB7xcAAAAJ&amp;citation_for_view=_8lB7xcAAAAJ:Tiz5es2fbqcC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-330-4285F4?logo=googlescholar&amp;labelColor=beige" alt="330 Google Scholar citations"> </a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ECCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/eccv20_f3net-480.webp 480w,/assets/img/publication_preview/eccv20_f3net-800.webp 800w,/assets/img/publication_preview/eccv20_f3net-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/eccv20_f3net.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="eccv20_f3net.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="DBLP:conf/eccv/QianYSCS20" class="col-sm-8"> <div class="title">Thinking in Frequency: Face Forgery Detection by Mining Frequency-Aware Clues</div> <div class="author"> Yuyang Qian , Guojun Yin, <em>Lu Sheng*</em>, Zixuan Chen, and <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a> </div> <div class="periodical"> <em>In European Conference on Computer Vision</em> , 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2007.09355" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123570086.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=_8lB7xcAAAAJ&amp;citation_for_view=_8lB7xcAAAAJ:tOudhMTPpwUC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-670-4285F4?logo=googlescholar&amp;labelColor=beige" alt="670 Google Scholar citations"> </a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" rel="external nofollow noopener" target="_blank">IEEE T-PAMI</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tpami19_visibility-480.webp 480w,/assets/img/publication_preview/tpami19_visibility-800.webp 800w,/assets/img/publication_preview/tpami19_visibility-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/tpami19_visibility.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tpami19_visibility.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="DBLP:journals/pami/ShengCCPN19" class="col-sm-8"> <div class="title">Visibility Constrained Generative Model for Depth-Based 3D Facial Pose Tracking</div> <div class="author"> <em>Lu Sheng</em>, Jianfei Cai, Tat-Jen Cham, Vladimir Pavlovic, and <a href="https://www.ee.cuhk.edu.hk/~knngan/" rel="external nofollow noopener" target="_blank">King Ngi Ngan</a> </div> <div class="periodical"> <em>IEEE Trans. Pattern Anal. Mach. Intell.</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/1905.02114" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://www.computer.org/csdl/journal/tp/2019/08/08502935/14C6d2crLdS" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr19_sdgan-480.webp 480w,/assets/img/publication_preview/cvpr19_sdgan-800.webp 800w,/assets/img/publication_preview/cvpr19_sdgan-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/cvpr19_sdgan.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr19_sdgan.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="DBLP:conf/cvpr/YinLSYWS19" class="col-sm-8"> <div class="title">Semantics Disentangling for Text-To-Image Generation</div> <div class="author"> Guojun Yin , Bin Liu, <em>Lu Sheng*</em> , Nenghai Yu, <a href="https://www.ee.cuhk.edu.hk/~xgwang/" rel="external nofollow noopener" target="_blank">Xiaogang Wang</a>, and <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a> </div> <div class="periodical"> <em>In IEEE Conference on Computer Vision and Pattern Recognition</em> (<b style="color:#b71c1c">Oral Presentation</b>) , 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Yin_Semantics_Disentangling_for_Text-To-Image_Generation_CVPR_2019_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=_8lB7xcAAAAJ&amp;citation_for_view=_8lB7xcAAAAJ:SP6oXDckpogC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-230-4285F4?logo=googlescholar&amp;labelColor=beige" alt="230 Google Scholar citations"> </a> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%6C%73%68%65%6E%67@%62%75%61%61.%65%64%75.%63%6E" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=_8lB7xcAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/LucasSheng" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://twitter.com/SHENGLui1989" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> <a href="https://dblp.org/pid/132/1772.html" title="DBLP" rel="external nofollow noopener" target="_blank"><i class="ai ai-dblp"></i></a> </div> <div class="contact-note"></div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Lu Sheng. Last updated: September 14, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>