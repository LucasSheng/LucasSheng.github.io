<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Publications | Lu Sheng · 盛律 </title> <meta name="author" content="Lu Sheng"> <meta name="description" content="Please visit my &lt;a href='https://scholar.google.com.hk/citations?user=_8lB7xcAAAAJ&amp;hl=en'&gt;Google Scholar profile&lt;/a&gt; to check out my up-to-date publication list."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://lucassheng.github.io/publications/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Lu Sheng · 盛律 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description">Please visit my <a href="https://scholar.google.com.hk/citations?user=_8lB7xcAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Google Scholar profile</a> to check out my up-to-date publication list.</p> </header> <article> <p><strong>#</strong> indicates equal contributions; <strong>*</strong> indicates corresponding authors.</p> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">Preprint</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tr24_llm_eval-480.webp 480w,/assets/img/publication_preview/tr24_llm_eval-800.webp 800w,/assets/img/publication_preview/tr24_llm_eval-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/tr24_llm_eval.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tr24_llm_eval.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:journals/corr/abs-2401-15071" class="col-sm-8"> <div class="title">From GPT-4 to Gemini and Beyond: Assessing the Landscape of MLLMs on Generalizability, Trustworthiness and Causality through Four Modalities</div> <div class="author"> <a href="https://causallu.com/" rel="external nofollow noopener" target="_blank">Chaochao Lu</a>, Chen Qian, Guodong Zheng, Hongxing Fan, Hongzhi Gao , Jie Zhang, <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a>, Jingyi Deng, Jinlan Fu, Kexin Huang, and <span class="more-authors" title="click to view 26 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '26 more authors' ? 'Kunchang Li, Lijun Li, Limin Wang, Lu Sheng, Meiqi Chen, Ming Zhang, Qibing Ren, Sirui Chen, Tao Gui, Wanli Ouyang, Yali Wang, Yan Teng, Yaru Wang, Yi Wang, Yinan He, Yingchun Wang, Yixu Wang, Yongting Zhang, Yu Qiao, Yujiong Shen, Yurong Mou, Yuxi Chen, Zaibin Zhang, Zhelun Shi, Zhenfei Yin, Zhipin Wang' : '26 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">26 more authors</span> </div> <div class="periodical"> <em>CoRR</em>(authors listed in alphabetical order) , 2024 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">Preprint</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/eccv24_minedreamer-480.webp 480w,/assets/img/publication_preview/eccv24_minedreamer-800.webp 800w,/assets/img/publication_preview/eccv24_minedreamer-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/eccv24_minedreamer.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="eccv24_minedreamer.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:journals/corr/abs-2403-12037" class="col-sm-8"> <div class="title">MineDreamer: Learning to Follow Instructions via Chain-of-Imagination for Simulated-World Control</div> <div class="author"> <a href="https://github.com/Zhoues" rel="external nofollow noopener" target="_blank">Enshen Zhou</a>, Yiran Qin, <a href="https://scholar.google.com.hk/citations?user=ngPR1dIAAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Zhenfei Yin</a>, Yuzhou Huang , <a href="http://www.zhangruimao.site/" rel="external nofollow noopener" target="_blank">Ruimao Zhang</a>, <em>Lu Sheng</em>, <a href="https://mmlab.siat.ac.cn/yuqiao" rel="external nofollow noopener" target="_blank">Yu Qiao</a>, and <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a> </div> <div class="periodical"> <em>CoRR</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2403.12037" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/Zhoues/MineDreamer" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://sites.google.com/view/minedreamer/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">Preprint</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/eccv24_ch3ef-480.webp 480w,/assets/img/publication_preview/eccv24_ch3ef-800.webp 800w,/assets/img/publication_preview/eccv24_ch3ef-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/eccv24_ch3ef.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="eccv24_ch3ef.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:journals/corr/abs-2403-17830" class="col-sm-8"> <div class="title">Assessment of Multimodal Large Language Models in Alignment with Human Values</div> <div class="author"> Zhelun Shi , Zhipin Wang, Hongxing Fan , Zaibin Zhang, Lijun Li , Yongting Zhang, <a href="https://scholar.google.com.hk/citations?user=ngPR1dIAAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Zhenfei Yin</a>, <em>Lu Sheng</em>, <a href="https://mmlab.siat.ac.cn/yuqiao" rel="external nofollow noopener" target="_blank">Yu Qiao</a>, and <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a> </div> <div class="periodical"> <em>CoRR</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2403.17830" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://openlamm.github.io/ch3ef/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">Preprint</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/eccv24_rh20tp-480.webp 480w,/assets/img/publication_preview/eccv24_rh20tp-800.webp 800w,/assets/img/publication_preview/eccv24_rh20tp-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/eccv24_rh20tp.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="eccv24_rh20tp.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:journals/corr/abs-2403-19622" class="col-sm-8"> <div class="title">RH20T-P: A Primitive-Level Robotic Dataset Towards Composable Generalization Agents</div> <div class="author"> Zeren Chen, Zhelun Shi , Xiaoya Lu, Lehan He, Sucheng Qian, <a href="https://fang-haoshu.github.io/" rel="external nofollow noopener" target="_blank">Haoshu Fang</a>, <a href="https://scholar.google.com.hk/citations?user=ngPR1dIAAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Zhenfei Yin</a>, <a href="https://wlouyang.github.io/" rel="external nofollow noopener" target="_blank">Wanli Ouyang</a>, <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a>, <a href="https://mmlab.siat.ac.cn/yuqiao" rel="external nofollow noopener" target="_blank">Yu Qiao</a>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Cewu Lu, Lu Sheng' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">2 more authors</span> </div> <div class="periodical"> <em>CoRR</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2403.19622" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://sites.google.com/view/rh20t-primitive/main" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr24_epidiff-480.webp 480w,/assets/img/publication_preview/cvpr24_epidiff-800.webp 800w,/assets/img/publication_preview/cvpr24_epidiff-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/cvpr24_epidiff.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr24_epidiff.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:journals/corr/abs-2312-06725" class="col-sm-8"> <div class="title">EpiDiff: Enhancing Multi-View Synthesis via Localized Epipolar-Constrained Diffusion</div> <div class="author"> Zehuan Huang#, Hao Wen#, Junting Dong# , Yaohui Wang, Yangguang Li, Xinyuan Chen, Yan-Pei Cao, Ding Liang, <a href="https://mmlab.siat.ac.cn/yuqiao" rel="external nofollow noopener" target="_blank">Yu Qiao</a> , Bo Dai*, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Lu Sheng*' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">1 more author</span> </div> <div class="periodical"> <em>In IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2312.06725" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Huang_EpiDiff_Enhancing_Multi-View_Synthesis_via_Localized_Epipolar-Constrained_Diffusion_CVPR_2024_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/huanngzh/EpiDiff" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://huanngzh.github.io/EpiDiff/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr24_mp5-480.webp 480w,/assets/img/publication_preview/cvpr24_mp5-800.webp 800w,/assets/img/publication_preview/cvpr24_mp5-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/cvpr24_mp5.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr24_mp5.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:journals/corr/abs-2312-07472" class="col-sm-8"> <div class="title">MP5: A Multi-modal Open-ended Embodied System in Minecraft via Active Perception</div> <div class="author"> Yiran Qin#, Enshen Zhou#, Qichang Liu#, <a href="https://scholar.google.com.hk/citations?user=ngPR1dIAAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Zhenfei Yin</a>, <em>Lu Sheng*</em> , <a href="http://www.zhangruimao.site/" rel="external nofollow noopener" target="_blank">Ruimao Zhang*</a>, <a href="https://mmlab.siat.ac.cn/yuqiao" rel="external nofollow noopener" target="_blank">Yu Qiao</a>, and <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a> </div> <div class="periodical"> <em>In IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2312.07472" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Qin_MP5_A_Multi-modal_Open-ended_Embodied_System_in_Minecraft_via_Active_CVPR_2024_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/IranQin/MP5" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://iranqin.github.io/MP5.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ICLR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/iclr24_octavius-480.webp 480w,/assets/img/publication_preview/iclr24_octavius-800.webp 800w,/assets/img/publication_preview/iclr24_octavius-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/iclr24_octavius.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="iclr24_octavius.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="chen2023octavius" class="col-sm-8"> <div class="title">Octavius: Mitigating Task Interference in MLLMs via LoRA-MoE</div> <div class="author"> Zeren Chen#, Ziqin Wang# , Zhen Wang , Huayang Liu, <a href="https://scholar.google.com.hk/citations?user=ngPR1dIAAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Zhenfei Yin</a> , Si Liu, <em>Lu Sheng*</em>, <a href="https://wlouyang.github.io/" rel="external nofollow noopener" target="_blank">Wanli Ouyang</a>, <a href="https://mmlab.siat.ac.cn/yuqiao" rel="external nofollow noopener" target="_blank">Yu Qiao</a>, and <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao*</a> </div> <div class="periodical"> <em>In International Conference on Learning Representations</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2311.02684" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://openreview.net/pdf?id=rTDyN8yajn" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/OpenGVLab/LAMM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://openlamm.github.io/paper_list/Octavius" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">AAAI</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/aaai24_3dwssg-480.webp 480w,/assets/img/publication_preview/aaai24_3dwssg-800.webp 800w,/assets/img/publication_preview/aaai24_3dwssg-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/aaai24_3dwssg.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="aaai24_3dwssg.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/aaai/LiXZZYS024" class="col-sm-8"> <div class="title">Multi-Modality Affinity Inference for Weakly Supervised 3D Semantic Segmentation</div> <div class="author"> Xiawei Li , Qingyuan Xu, <a href="https://hellojing89.github.io/" rel="external nofollow noopener" target="_blank">Jing Zhang*</a> , Tianyi Zhang, <a href="https://yuqian1023.github.io" rel="external nofollow noopener" target="_blank">Qian Yu</a>, <em>Lu Sheng</em>, and <a href="https://www.cs.hku.hk/people/academic-staff/dongxu" rel="external nofollow noopener" target="_blank">Dong Xu</a> </div> <div class="periodical"> <em>In Thirty-Eighth AAAI Conference on Artificial Intelligence</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2312.16578" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://doi.org/10.1609/aaai.v38i4.28106" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/Sunny599/AAAI24-3DWSSS-MMA" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">AAAI</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/aaai24_dfzsl-480.webp 480w,/assets/img/publication_preview/aaai24_dfzsl-800.webp 800w,/assets/img/publication_preview/aaai24_dfzsl-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/aaai24_dfzsl.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="aaai24_dfzsl.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/aaai/TangZYYSX24" class="col-sm-8"> <div class="title">Data-Free Generalized Zero-Shot Learning</div> <div class="author"> Bowen Tang, Jing Zhang# , Long Yan, <a href="https://yuqian1023.github.io" rel="external nofollow noopener" target="_blank">Qian Yu</a>, <em>Lu Sheng</em>, and <a href="https://www.cs.hku.hk/people/academic-staff/dongxu" rel="external nofollow noopener" target="_blank">Dong Xu</a> </div> <div class="periodical"> <em>In Thirty-Eighth AAAI Conference on Artificial Intelligence</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2401.15657" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://doi.org/10.1609/aaai.v38i6.28316" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/ylong4/DFZSL" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">Preprint</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tr23_chef-480.webp 480w,/assets/img/publication_preview/tr23_chef-800.webp 800w,/assets/img/publication_preview/tr23_chef-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/tr23_chef.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tr23_chef.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:journals/corr/abs-2311-02692" class="col-sm-8"> <div class="title">ChEF: A Comprehensive Evaluation Framework for Standardized Assessment of Multimodal Large Language Models</div> <div class="author"> Zhelun Shi , Zhipin Wang, Hongxing Fan, <a href="https://scholar.google.com.hk/citations?user=ngPR1dIAAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Zhenfei Yin</a>, <em>Lu Sheng</em>, <a href="https://mmlab.siat.ac.cn/yuqiao" rel="external nofollow noopener" target="_blank">Yu Qiao</a>, and <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a> </div> <div class="periodical"> <em>CoRR</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2311.02692" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/OpenGVLab/LAMM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://openlamm.github.io/paper_list/ChEF" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">NeurIPS</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/neurips23_lamm-480.webp 480w,/assets/img/publication_preview/neurips23_lamm-800.webp 800w,/assets/img/publication_preview/neurips23_lamm-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/neurips23_lamm.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="neurips23_lamm.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/nips/YinWCSLLH0S0SO23" class="col-sm-8"> <div class="title">LAMM: Language-Assisted Multi-Modal Instruction-Tuning Dataset, Framework, and Benchmark</div> <div class="author"> Zhenfei Yin#, Jiong Wang#, Jianjian Cao#, Zhelun Shi# , Dingning Liu, Mukai Li, Xiaoshui Huang , Zhiyong Wang, <em>Lu Sheng</em>, Lei Bai*, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Jing Shao*, Wanli Ouyang' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">2 more authors</span> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2306.06687" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="http://papers.nips.cc/paper_files/paper/2023/hash/548a41b9cac6f50dccf7e63e9e1b1b9b-Abstract-Datasets_and_Benchmarks.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://www.youtube.com/watch?v=M7XlIe8hhPk" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://openlamm.github.io/paper_list/LAMM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr23_siamese_detr-480.webp 480w,/assets/img/publication_preview/cvpr23_siamese_detr-800.webp 800w,/assets/img/publication_preview/cvpr23_siamese_detr-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/cvpr23_siamese_detr.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr23_siamese_detr.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/cvpr/ChenHLTWSLS23" class="col-sm-8"> <div class="title">Siamese DETR</div> <div class="author"> Zeren Chen#, Gengshi Huang#, Wei Li, Jianing Teng , Kun Wang, <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a>, <a href="https://www.mmlab-ntu.com/person/ccloy/" rel="external nofollow noopener" target="_blank">Chen Change Loy</a>, and <em>Lu Sheng*</em> </div> <div class="periodical"> <em>In IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Siamese_DETR_CVPR_2023_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/Zx55/SiameseDETR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr23_vlsat-480.webp 480w,/assets/img/publication_preview/cvpr23_vlsat-800.webp 800w,/assets/img/publication_preview/cvpr23_vlsat-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/cvpr23_vlsat.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr23_vlsat.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/cvpr/WangCZ0TS23" class="col-sm-8"> <div class="title">VL-SAT: Visual-Linguistic Semantics Assisted Training for 3D Semantic Scene Graph Prediction in Point Cloud</div> <div class="author"> Ziqin Wang, Bowen Cheng, Lichen Zhao, <a href="https://www.cs.hku.hk/people/academic-staff/dongxu" rel="external nofollow noopener" target="_blank">Dong Xu</a>, Yang Tang*, and <em>Lu Sheng*</em> </div> <div class="periodical"> <em>In IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (<b style="color:#b71c1c">Highlight Poster</b>) , 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_VL-SAT_Visual-Linguistic_Semantics_Assisted_Training_for_3D_Semantic_Scene_Graph_CVPR_2023_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/wz7in/CVPR2023-VLSAT" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">IEEE T-CSVT</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/csvt23_fegqa-480.webp 480w,/assets/img/publication_preview/csvt23_fegqa-800.webp 800w,/assets/img/publication_preview/csvt23_fegqa-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/csvt23_fegqa.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="csvt23_fegqa.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:journals/tcsv/ZhaoCZSXZZWF23" class="col-sm-8"> <div class="title">Toward Explainable 3D Grounded Visual Question Answering: A New Benchmark and Strong Baseline</div> <div class="author"> Lichen Zhao, Daigang Cai, <a href="https://hellojing89.github.io/" rel="external nofollow noopener" target="_blank">Jing Zhang</a>, <em>Lu Sheng</em>, <a href="https://www.cs.hku.hk/people/academic-staff/dongxu" rel="external nofollow noopener" target="_blank">Dong Xu</a>, Rui Zheng, Yinjie Zhao , Lipeng Wang, and Xibo Fan </div> <div class="periodical"> <em>IEEE Trans. Circuits Syst. Video Technol.</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2209.12028" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://ieeexplore.ieee.org/document/9984686" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/zlccccc/3DVL_Codebase" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">Guest Editorial</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/jsps-480.webp 480w,/assets/img/publication_preview/jsps-800.webp 800w,/assets/img/publication_preview/jsps-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/jsps.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="jsps.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:journals/vlsisp/YuZSX23" class="col-sm-8"> <div class="title">Guest Editorial: Special Issue on Machine Learning and Signal Processing</div> <div class="author"> <a href="https://yuqian1023.github.io" rel="external nofollow noopener" target="_blank">Qian Yu</a>, Liang Zheng, <em>Lu Sheng</em>, and <a href="https://www.cs.hku.hk/people/academic-staff/dongxu" rel="external nofollow noopener" target="_blank">Dong Xu</a> </div> <div class="periodical"> <em>J. Signal Process. Syst.</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://link.springer.com/article/10.1007/s11265-022-01824-w" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ACM MM</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/mm23_360sod-480.webp 480w,/assets/img/publication_preview/mm23_360sod-800.webp 800w,/assets/img/publication_preview/mm23_360sod-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/mm23_360sod.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mm23_360sod.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/mm/ZhaoZYSZX23" class="col-sm-8"> <div class="title">Distortion-aware Transformer in 360 Salient Object Detection</div> <div class="author"> Yinjie Zhao, Lichen Zhao, <a href="https://yuqian1023.github.io" rel="external nofollow noopener" target="_blank">Qian Yu</a>, <em>Lu Sheng</em>, <a href="https://hellojing89.github.io/" rel="external nofollow noopener" target="_blank">Jing Zhang</a>, and <a href="https://www.cs.hku.hk/people/academic-staff/dongxu" rel="external nofollow noopener" target="_blank">Dong Xu</a> </div> <div class="periodical"> <em>In Proceedings of the 31st ACM International Conference on Multimedia</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2308.03359" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/yjzhao19981027/DATFormer" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83" rel="external nofollow noopener" target="_blank">IEEE T-IP</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tip22_vpu-480.webp 480w,/assets/img/publication_preview/tip22_vpu-800.webp 800w,/assets/img/publication_preview/tip22_vpu-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/tip22_vpu.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tip22_vpu.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:journals/tip/WangSGX22" class="col-sm-8"> <div class="title">VPU: A Video-Based Point Cloud Upsampling Framework</div> <div class="author"> Kaisiyuan Wang, <em>Lu Sheng</em>, Shuhang Gu, and <a href="https://www.cs.hku.hk/people/academic-staff/dongxu" rel="external nofollow noopener" target="_blank">Dong Xu</a> </div> <div class="periodical"> <em>IEEE Trans. Image Process.</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/TIP.2022.3166627" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ECCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/eccv22_rgbd_registration-480.webp 480w,/assets/img/publication_preview/eccv22_rgbd_registration-800.webp 800w,/assets/img/publication_preview/eccv22_rgbd_registration-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/eccv22_rgbd_registration.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="eccv22_rgbd_registration.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/eccv/WangHCZSX22" class="col-sm-8"> <div class="title">Improving RGB-D Point Cloud Registration by Learning Multi-scale Local Linear Transformation</div> <div class="author"> Ziming Wang*, Xiaoliang Huo*, Zhenghao Chen, <a href="https://hellojing89.github.io/" rel="external nofollow noopener" target="_blank">Jing Zhang</a>, Lu Sheng#, and <a href="https://www.cs.hku.hk/people/academic-staff/dongxu" rel="external nofollow noopener" target="_blank">Dong Xu</a> </div> <div class="periodical"> <em>In European Conference on Computer Vision</em> , 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2208.14893" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136920175.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/514DNA/LLT" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ECCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/eccv22_sketchsampler-480.webp 480w,/assets/img/publication_preview/eccv22_sketchsampler-800.webp 800w,/assets/img/publication_preview/eccv22_sketchsampler-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/eccv22_sketchsampler.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="eccv22_sketchsampler.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/eccv/GaoYSSX22" class="col-sm-8"> <div class="title">SketchSampler: Sketch-Based 3D Reconstruction via View-Dependent Depth Sampling</div> <div class="author"> Chenjian Gao, <a href="https://yuqian1023.github.io" rel="external nofollow noopener" target="_blank">Qian Yu</a>, <em>Lu Sheng</em>, Yi-Zhe Song, and <a href="https://www.cs.hku.hk/people/academic-staff/dongxu" rel="external nofollow noopener" target="_blank">Dong Xu</a> </div> <div class="periodical"> <em>In European Conference on Computer Vision</em> , 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2208.06880" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136610457.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/cjeen/sketchsampler" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ECCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/eccv22_x_learner-480.webp 480w,/assets/img/publication_preview/eccv22_x_learner-800.webp 800w,/assets/img/publication_preview/eccv22_x_learner-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/eccv22_x_learner.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="eccv22_x_learner.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/eccv/HeHCTWYSLQS22" class="col-sm-8"> <div class="title">X-Learner: Learning Cross Sources and Tasks for Universal Visual Representation</div> <div class="author"> Yinan He, Gengshi Huang, Siyu Chen, Jianing Teng , Kun Wang, <a href="https://scholar.google.com.hk/citations?user=ngPR1dIAAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Zhenfei Yin</a>, <em>Lu Sheng</em> , <a href="https://liuziwei7.github.io/" rel="external nofollow noopener" target="_blank">Ziwei Liu</a>, <a href="https://mmlab.siat.ac.cn/yuqiao" rel="external nofollow noopener" target="_blank">Yu Qiao</a>, and <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a> </div> <div class="periodical"> <em>In European Conference on Computer Vision</em> , 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2203.08764" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136860495.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr22_3djcg-480.webp 480w,/assets/img/publication_preview/cvpr22_3djcg-800.webp 800w,/assets/img/publication_preview/cvpr22_3djcg-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/cvpr22_3djcg.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr22_3djcg.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/cvpr/CaiZZSX22" class="col-sm-8"> <div class="title">3DJCG: A Unified Framework for Joint Dense Captioning and Visual Grounding on 3D Point Clouds</div> <div class="author"> Daigang Cai, Lichen Zhao, <a href="https://hellojing89.github.io/" rel="external nofollow noopener" target="_blank">Jing Zhang</a>, <em>Lu Sheng</em>, and <a href="https://www.cs.hku.hk/people/academic-staff/dongxu" rel="external nofollow noopener" target="_blank">Dong Xu</a> </div> <div class="periodical"> <em>In IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (<b style="color:#b71c1c">Oral Presentation</b>) , 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_3DJCG_A_Unified_Framework_for_Joint_Dense_Captioning_and_Visual_CVPR_2022_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/zlccccc/3DVL_Codebase" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">AAAI</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/aaai22_danceformer-480.webp 480w,/assets/img/publication_preview/aaai22_danceformer-800.webp 800w,/assets/img/publication_preview/aaai22_danceformer-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/aaai22_danceformer.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="aaai22_danceformer.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/aaai/LiZZS22" class="col-sm-8"> <div class="title">DanceFormer: Music Conditioned 3D Dance Generation with Parametric Motion Transformer</div> <div class="author"> Buyu Li, Yongchi Zhao, Zhelun Shi, and <em>Lu Sheng</em> </div> <div class="periodical"> <em>In Thirty-Sixth AAAI Conference on Artificial Intelligence</em> , 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20014" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/libuyu/PhantomDanceDataset" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">IEEE T-CSVT</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tcsvt21_spu-480.webp 480w,/assets/img/publication_preview/tcsvt21_spu-800.webp 800w,/assets/img/publication_preview/tcsvt21_spu-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/tcsvt21_spu.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tcsvt21_spu.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:journals/tcsv/WangSGX21" class="col-sm-8"> <div class="title">Sequential Point Cloud Upsampling by Exploiting Multi-Scale Temporal Dependency</div> <div class="author"> Kaisiyuan Wang, <em>Lu Sheng</em>, Shuhang Gu, and <a href="https://www.cs.hku.hk/people/academic-staff/dongxu" rel="external nofollow noopener" target="_blank">Dong Xu</a> </div> <div class="periodical"> <em>IEEE Trans. Circuits Syst. Video Technol.</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://ieeexplore.ieee.org/document/9512063" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">IEEE T-CSVT</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tcsvt21_t3d-480.webp 480w,/assets/img/publication_preview/tcsvt21_t3d-800.webp 800w,/assets/img/publication_preview/tcsvt21_t3d-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/tcsvt21_t3d.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tcsvt21_t3d.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:journals/tcsv/ZhaoGXS21" class="col-sm-8"> <div class="title">Transformer3D-Det: Improving 3D Object Detection by Vote Refinement</div> <div class="author"> Lichen Zhao, Jinyang Guo, <a href="https://www.cs.hku.hk/people/academic-staff/dongxu" rel="external nofollow noopener" target="_blank">Dong Xu</a>, and <em>Lu Sheng</em> </div> <div class="periodical"> <em>IEEE Trans. Circuits Syst. Video Technol.</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://ieeexplore.ieee.org/document/9504551" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83" rel="external nofollow noopener" target="_blank">IEEE T-IP</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tip21_pcgtal-480.webp 480w,/assets/img/publication_preview/tip21_pcgtal-800.webp 800w,/assets/img/publication_preview/tip21_pcgtal-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/tip21_pcgtal.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tip21_pcgtal.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:journals/tip/SuXSO21" class="col-sm-8"> <div class="title">PCG-TAL: Progressive Cross-Granularity Cooperation for Temporal Action Localization</div> <div class="author"> Rui Su, <a href="https://www.cs.hku.hk/people/academic-staff/dongxu" rel="external nofollow noopener" target="_blank">Dong Xu</a>, <em>Lu Sheng</em>, and <a href="https://wlouyang.github.io/" rel="external nofollow noopener" target="_blank">Wanli Ouyang</a> </div> <div class="periodical"> <em>IEEE Trans. Image Process.</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://ieeexplore.ieee.org/abstract/document/9298475" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">IEEE T-MM</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tmm21_npc-480.webp 480w,/assets/img/publication_preview/tmm21_npc-800.webp 800w,/assets/img/publication_preview/tmm21_npc-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/tmm21_npc.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tmm21_npc.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:journals/tmm/CheungSN21" class="col-sm-8"> <div class="title">Motion Compensated Virtual View Synthesis Using Novel Particle Cell</div> <div class="author"> Chi Ho Cheung, <em>Lu Sheng</em>, and <a href="https://www.ee.cuhk.edu.hk/~knngan/" rel="external nofollow noopener" target="_blank">King Ngi Ngan</a> </div> <div class="periodical"> <em>IEEE Trans. Multim.</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://ieeexplore.ieee.org/document/9126202" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr21_forgerynet-480.webp 480w,/assets/img/publication_preview/cvpr21_forgerynet-800.webp 800w,/assets/img/publication_preview/cvpr21_forgerynet-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/cvpr21_forgerynet.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr21_forgerynet.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/cvpr/HeGCZYSSS021" class="col-sm-8"> <div class="title">ForgeryNet: A Versatile Benchmark for Comprehensive Forgery Analysis</div> <div class="author"> Yinan He#, Bei Gan#, Siyu Chen , Yichun Zhou , Guojun Yin, Luchuan Song, <em>Lu Sheng</em>, <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao*</a> , and <a href="https://liuziwei7.github.io/" rel="external nofollow noopener" target="_blank">Ziwei Liu</a> </div> <div class="periodical"> <em>In IEEE Conference on Computer Vision and Pattern Recognition</em> (<b style="color:#b71c1c">Oral Presentation</b>) , 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/He_ForgeryNet_A_Versatile_Benchmark_for_Comprehensive_Forgery_Analysis_CVPR_2021_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/yinanhe/forgerynet" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://yinanhe.github.io/projects/forgerynet.html#" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=_8lB7xcAAAAJ&amp;citation_for_view=_8lB7xcAAAAJ:4fKUyHm3Qg0C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-110-4285F4?logo=googlescholar&amp;labelColor=beige" alt="110 Google Scholar citations"> </a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr21_brnet-480.webp 480w,/assets/img/publication_preview/cvpr21_brnet-800.webp 800w,/assets/img/publication_preview/cvpr21_brnet-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/cvpr21_brnet.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr21_brnet.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/cvpr/ChengSSY021" class="col-sm-8"> <div class="title">Back-Tracing Representative Points for Voting-Based 3D Object Detection in Point Clouds</div> <div class="author"> Bowen Cheng, <em>Lu Sheng*</em>, Shaoshuai Shi, Ming Yang, and <a href="https://www.cs.hku.hk/people/academic-staff/dongxu" rel="external nofollow noopener" target="_blank">Dong Xu</a> </div> <div class="periodical"> <em>In IEEE Conference on Computer Vision and Pattern Recognition</em> , 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Cheng_Back-Tracing_Representative_Points_for_Voting-Based_3D_Object_Detection_in_Point_CVPR_2021_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/cheng052/BRNet" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ICCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/iccv21_3dvg-480.webp 480w,/assets/img/publication_preview/iccv21_3dvg-800.webp 800w,/assets/img/publication_preview/iccv21_3dvg-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/iccv21_3dvg.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="iccv21_3dvg.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/iccv/ZhaoCS021" class="col-sm-8"> <div class="title">3DVG-Transformer: Relation Modeling for Visual Grounding on Point Clouds</div> <div class="author"> Lichen Zhao, Daigang Cai, <em>Lu Sheng</em>, and <a href="https://www.cs.hku.hk/people/academic-staff/dongxu" rel="external nofollow noopener" target="_blank">Dong Xu</a> </div> <div class="periodical"> <em>In IEEE/CVF International Conference on Computer Vision</em> (<b style="color:#b71c1c">1st place</b> at 3D Object Localization Challenge at the CVPR 2021, 1st Workshop on Language for 3D Scenes) , 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_3DVG-Transformer_Relation_Modeling_for_Visual_Grounding_on_Point_Clouds_ICCV_2021_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/zlccccc/3DVG-Transformer" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=_8lB7xcAAAAJ&amp;citation_for_view=_8lB7xcAAAAJ:LPZeul_q3PIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-100-4285F4?logo=googlescholar&amp;labelColor=beige" alt="100 Google Scholar citations"> </a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ICCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/iccv21_styleformer-480.webp 480w,/assets/img/publication_preview/iccv21_styleformer-800.webp 800w,/assets/img/publication_preview/iccv21_styleformer-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/iccv21_styleformer.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="iccv21_styleformer.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/iccv/WuHS021" class="col-sm-8"> <div class="title">StyleFormer: Real-time Arbitrary Style Transfer via Parametric Style Composition</div> <div class="author"> Xiaolei Wu, Zhihao Hu, <em>Lu Sheng</em>, and <a href="https://www.cs.hku.hk/people/academic-staff/dongxu" rel="external nofollow noopener" target="_blank">Dong Xu</a> </div> <div class="periodical"> <em>In IEEE/CVF International Conference on Computer Vision</em> , 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Wu_StyleFormer_Real-Time_Arbitrary_Style_Transfer_via_Parametric_Style_Composition_ICCV_2021_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/wxl-stars/pytorchstyleformer" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ACM MM</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/mm21_votehmr-480.webp 480w,/assets/img/publication_preview/mm21_votehmr-800.webp 800w,/assets/img/publication_preview/mm21_votehmr-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/mm21_votehmr.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mm21_votehmr.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/mm/LiuRS21" class="col-sm-8"> <div class="title">VoteHMR: Occlusion-Aware Voting Network for Robust 3D Human Mesh Recovery from Partial Point Clouds</div> <div class="author"> Guanze Liu, Yu Rong, and <em>Lu Sheng*</em> </div> <div class="periodical"> <em>In Proceedings of the 29th ACM International Conference on Multimedia</em> (<b style="color:#b71c1c">Oral Presentation</b>) , 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/https://arxiv.org/abs/2110.08729" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://dl.acm.org/doi/abs/10.1145/3474085.3475309" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/hanabi7/VoteHMR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">WACV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/wacv21_increaco-480.webp 480w,/assets/img/publication_preview/wacv21_increaco-800.webp 800w,/assets/img/publication_preview/wacv21_increaco-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/wacv21_increaco.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="wacv21_increaco.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/wacv/YangSJW0021" class="col-sm-8"> <div class="title">IncreACO: Incrementally Learned Automatic Check-out with Photorealistic Exemplar Augmentation</div> <div class="author"> Yandan Yang, <em>Lu Sheng</em>, Xiaolong Jiang , Haochen Wang, <a href="https://www.cs.hku.hk/people/academic-staff/dongxu" rel="external nofollow noopener" target="_blank">Dong Xu</a>, and Xianbin Cao </div> <div class="periodical"> <em>In IEEE Winter Conference on Applications of Computer Vision</em> , 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://ieeexplore.ieee.org/document/9423423" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://openaccess.thecvf.com/content/WACV2021/papers/Yang_IncreACO_Incrementally_Learned_Automatic_Check-Out_With_Photorealistic_Exemplar_Augmentation_WACV_2021_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">IJCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ijcv20_highquality-480.webp 480w,/assets/img/publication_preview/ijcv20_highquality-800.webp 800w,/assets/img/publication_preview/ijcv20_highquality-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/ijcv20_highquality.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ijcv20_highquality.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:journals/ijcv/ShengPGSL20" class="col-sm-8"> <div class="title">High-Quality Video Generation from Static Structural Annotations</div> <div class="author"> <em>Lu Sheng</em>, Junting Pan, Jiaming Guo, <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a>, and <a href="https://www.mmlab-ntu.com/person/ccloy/" rel="external nofollow noopener" target="_blank">Chen Change Loy</a> </div> <div class="periodical"> <em>Int. J. Comput. Vis.</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="https://link.springer.com/article/10.1007/s11263-020-01334-x" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/junting/seg2vid" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">AAAI</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/aaai20_msn-480.webp 480w,/assets/img/publication_preview/aaai20_msn-800.webp 800w,/assets/img/publication_preview/aaai20_msn-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/aaai20_msn.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="aaai20_msn.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/aaai/LiuSYS020" class="col-sm-8"> <div class="title">Morphing and Sampling Network for Dense Point Cloud Completion</div> <div class="author"> Minghua Liu, <em>Lu Sheng</em>, Sheng Yang, <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a>, and Shi-Min Hu </div> <div class="periodical"> <em>In The Thirty-Fourth AAAI Conference on Artificial Intelligence</em> , 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="https://cseweb.ucsd.edu//%C2%A0mil070/projects/AAAI2020/paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/Colin97/MSN-Point-Cloud-Completion" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=_8lB7xcAAAAJ&amp;citation_for_view=_8lB7xcAAAAJ:Tiz5es2fbqcC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-310-4285F4?logo=googlescholar&amp;labelColor=beige" alt="310 Google Scholar citations"> </a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ECCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/eccv20_f3net-480.webp 480w,/assets/img/publication_preview/eccv20_f3net-800.webp 800w,/assets/img/publication_preview/eccv20_f3net-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/eccv20_f3net.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="eccv20_f3net.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/eccv/QianYSCS20" class="col-sm-8"> <div class="title">Thinking in Frequency: Face Forgery Detection by Mining Frequency-Aware Clues</div> <div class="author"> Yuyang Qian , Guojun Yin, <em>Lu Sheng</em>, Zixuan Chen, and <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a> </div> <div class="periodical"> <em>In European Conference on Computer Vision</em> , 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2007.09355" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123570086.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=_8lB7xcAAAAJ&amp;citation_for_view=_8lB7xcAAAAJ:tOudhMTPpwUC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-590-4285F4?logo=googlescholar&amp;labelColor=beige" alt="590 Google Scholar citations"> </a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ECCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/eccv20_oneshot_nas-480.webp 480w,/assets/img/publication_preview/eccv20_oneshot_nas-800.webp 800w,/assets/img/publication_preview/eccv20_oneshot_nas-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/eccv20_oneshot_nas.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="eccv20_oneshot_nas.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/eccv/GuoLLTSSY20" class="col-sm-8"> <div class="title">Powering One-Shot Topological NAS with Stabilized Share-Parameter Proxy</div> <div class="author"> Ronghao Guo, Chen Lin, Chuming Li, Keyu Tian , Ming Sun, <em>Lu Sheng</em>, and <a href="https://scholar.google.com/citations?user=rEYarG0AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Junjie Yan</a> </div> <div class="periodical"> <em>In European Conference on Computer Vision</em> , 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2005.10511" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123590613.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" rel="external nofollow noopener" target="_blank">IEEE T-PAMI</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tpami19_visibility-480.webp 480w,/assets/img/publication_preview/tpami19_visibility-800.webp 800w,/assets/img/publication_preview/tpami19_visibility-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/tpami19_visibility.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tpami19_visibility.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:journals/pami/ShengCCPN19" class="col-sm-8"> <div class="title">Visibility Constrained Generative Model for Depth-Based 3D Facial Pose Tracking</div> <div class="author"> <em>Lu Sheng</em>, Jianfei Cai, Tat-Jen Cham, Vladimir Pavlovic, and <a href="https://www.ee.cuhk.edu.hk/~knngan/" rel="external nofollow noopener" target="_blank">King Ngi Ngan</a> </div> <div class="periodical"> <em>IEEE Trans. Pattern Anal. Mach. Intell.</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/1905.02114" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://www.computer.org/csdl/journal/tp/2019/08/08502935/14C6d2crLdS" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">PRL</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/prl19_cascaded-480.webp 480w,/assets/img/publication_preview/prl19_cascaded-800.webp 800w,/assets/img/publication_preview/prl19_cascaded-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/prl19_cascaded.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="prl19_cascaded.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:journals/prl/WuLZNS19" class="col-sm-8"> <div class="title">Cascaded regression using landmark displacement for 3D face reconstruction</div> <div class="author"> Fanzi Wu, Songnan Li, Tianhao Zhao, <a href="https://www.ee.cuhk.edu.hk/~knngan/" rel="external nofollow noopener" target="_blank">King Ngi Ngan</a>, and <em>Lu Sheng</em> </div> <div class="periodical"> <em>Pattern Recognit. Lett.</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0167865518303933" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">VRIH</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/vrih19_bag-480.webp 480w,/assets/img/publication_preview/vrih19_bag-800.webp 800w,/assets/img/publication_preview/vrih19_bag-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/vrih19_bag.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="vrih19_bag.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:journals/vrih/DongS19" class="col-sm-8"> <div class="title">Bags of tricks for learning depth and camera motion from monocular videos</div> <div class="author"> Bowen Dong, and <em>Lu Sheng</em> </div> <div class="periodical"> <em>Virtual Real. Intell. Hardw.</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="https://www.sciencedirect.com/science/article/pii/S2096579619300658" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr19_gs3d-480.webp 480w,/assets/img/publication_preview/cvpr19_gs3d-800.webp 800w,/assets/img/publication_preview/cvpr19_gs3d-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/cvpr19_gs3d.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr19_gs3d.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/cvpr/LiOSZW19" class="col-sm-8"> <div class="title">GS3D: An Efficient 3D Object Detection Framework for Autonomous Driving</div> <div class="author"> Buyu Li, <a href="https://wlouyang.github.io/" rel="external nofollow noopener" target="_blank">Wanli Ouyang</a>, <em>Lu Sheng</em>, Xingyu Zeng, and <a href="https://www.ee.cuhk.edu.hk/~xgwang/" rel="external nofollow noopener" target="_blank">Xiaogang Wang</a> </div> <div class="periodical"> <em>In IEEE Conference on Computer Vision and Pattern Recognition</em> , 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_GS3D_An_Efficient_3D_Object_Detection_Framework_for_Autonomous_Driving_CVPR_2019_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=_8lB7xcAAAAJ&amp;citation_for_view=_8lB7xcAAAAJ:dshw04ExmUIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-380-4285F4?logo=googlescholar&amp;labelColor=beige" alt="380 Google Scholar citations"> </a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr19_sdgan-480.webp 480w,/assets/img/publication_preview/cvpr19_sdgan-800.webp 800w,/assets/img/publication_preview/cvpr19_sdgan-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/cvpr19_sdgan.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr19_sdgan.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/cvpr/YinLSYWS19" class="col-sm-8"> <div class="title">Semantics Disentangling for Text-To-Image Generation</div> <div class="author"> Guojun Yin , Bin Liu, <em>Lu Sheng</em> , Nenghai Yu, <a href="https://www.ee.cuhk.edu.hk/~xgwang/" rel="external nofollow noopener" target="_blank">Xiaogang Wang</a>, and <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a> </div> <div class="periodical"> <em>In IEEE Conference on Computer Vision and Pattern Recognition</em> (<b style="color:#b71c1c">Oral Presentation</b>) , 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Yin_Semantics_Disentangling_for_Text-To-Image_Generation_CVPR_2019_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=_8lB7xcAAAAJ&amp;citation_for_view=_8lB7xcAAAAJ:SP6oXDckpogC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-220-4285F4?logo=googlescholar&amp;labelColor=beige" alt="220 Google Scholar citations"> </a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr19_single-480.webp 480w,/assets/img/publication_preview/cvpr19_single-800.webp 800w,/assets/img/publication_preview/cvpr19_single-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/cvpr19_single.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr19_single.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/cvpr/Pan0JSSYW19" class="col-sm-8"> <div class="title">Video Generation From Single Semantic Label Map</div> <div class="author"> Junting Pan , Chengyu Wang, Xu Jia, <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a>, <em>Lu Sheng</em>, <a href="https://scholar.google.com/citations?user=rEYarG0AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Junjie Yan</a>, and <a href="https://www.ee.cuhk.edu.hk/~xgwang/" rel="external nofollow noopener" target="_blank">Xiaogang Wang</a> </div> <div class="periodical"> <em>In IEEE Conference on Computer Vision and Pattern Recognition</em> , 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Pan_Video_Generation_From_Single_Semantic_Label_Map_CVPR_2019_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/junting/seg2vid" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=_8lB7xcAAAAJ&amp;citation_for_view=_8lB7xcAAAAJ:KxtntwgDAa4C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-100-4285F4?logo=googlescholar&amp;labelColor=beige" alt="100 Google Scholar citations"> </a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr19_cag-480.webp 480w,/assets/img/publication_preview/cvpr19_cag-800.webp 800w,/assets/img/publication_preview/cvpr19_cag-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/cvpr19_cag.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr19_cag.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/cvpr/YinSLYWS19" class="col-sm-8"> <div class="title">Context and Attribute Grounded Dense Captioning</div> <div class="author"> Guojun Yin, <em>Lu Sheng</em> , Bin Liu , Nenghai Yu, <a href="https://www.ee.cuhk.edu.hk/~xgwang/" rel="external nofollow noopener" target="_blank">Xiaogang Wang</a>, and <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a> </div> <div class="periodical"> <em>In IEEE Conference on Computer Vision and Pattern Recognition</em> , 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Yin_Context_and_Attribute_Grounded_Dense_Captioning_CVPR_2019_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ICCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/iccv19_keyframe-480.webp 480w,/assets/img/publication_preview/iccv19_keyframe-800.webp 800w,/assets/img/publication_preview/iccv19_keyframe-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/iccv19_keyframe.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="iccv19_keyframe.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/iccv/Sheng0OW19" class="col-sm-8"> <div class="title">Unsupervised Collaborative Learning of Keyframe Detection and Visual Odometry Towards Monocular Deep SLAM</div> <div class="author"> <em>Lu Sheng</em> , Dan Xu, <a href="https://wlouyang.github.io/" rel="external nofollow noopener" target="_blank">Wanli Ouyang</a>, and <a href="https://www.ee.cuhk.edu.hk/~xgwang/" rel="external nofollow noopener" target="_blank">Xiaogang Wang</a> </div> <div class="periodical"> <em>In IEEE/CVF International Conference on Computer Vision</em> , 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Sheng_Unsupervised_Collaborative_Learning_of_Keyframe_Detection_and_Visual_Odometry_Towards_ICCV_2019_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ICCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/iccv19_reid-480.webp 480w,/assets/img/publication_preview/iccv19_reid-800.webp 800w,/assets/img/publication_preview/iccv19_reid-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/iccv19_reid.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="iccv19_reid.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/iccv/TangSZH19" class="col-sm-8"> <div class="title">Improving Pedestrian Attribute Recognition With Weakly-Supervised Multi-Scale Attribute-Specific Localization</div> <div class="author"> Chufeng Tang, <em>Lu Sheng</em> , Zhaoxiang Zhang, and Xiaolin Hu </div> <div class="periodical"> <em>In IEEE/CVF International Conference on Computer Vision</em> , 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Tang_Improving_Pedestrian_Attribute_Recognition_With_Weakly-Supervised_Multi-Scale_Attribute-Specific_Localization_ICCV_2019_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/chufengt/ALM-pedestrian-attribute" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=_8lB7xcAAAAJ&amp;citation_for_view=_8lB7xcAAAAJ:WbkHhVStYXYC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-150-4285F4?logo=googlescholar&amp;labelColor=beige" alt="150 Google Scholar citations"> </a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ICCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/iccv19_camp-480.webp 480w,/assets/img/publication_preview/iccv19_camp-800.webp 800w,/assets/img/publication_preview/iccv19_camp-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/iccv19_camp.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="iccv19_camp.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/iccv/WangLLSYWS19" class="col-sm-8"> <div class="title">CAMP: Cross-Modal Adaptive Message Passing for Text-Image Retrieval</div> <div class="author"> Zihao Wang, <a href="http://xh-liu.github.io/" rel="external nofollow noopener" target="_blank">Xihui Liu</a>, Hongsheng Li, <em>Lu Sheng</em>, <a href="https://scholar.google.com/citations?user=rEYarG0AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Junjie Yan</a>, <a href="https://www.ee.cuhk.edu.hk/~xgwang/" rel="external nofollow noopener" target="_blank">Xiaogang Wang</a>, and <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a> </div> <div class="periodical"> <em>In IEEE/CVF International Conference on Computer Vision</em> , 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/https://arxiv.org/abs/1909.05506" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_CAMP_Cross-Modal_Adaptive_Message_Passing_for_Text-Image_Retrieval_ICCV_2019_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/ZihaoWang-CV/CAMP_iccv19" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=_8lB7xcAAAAJ&amp;citation_for_view=_8lB7xcAAAAJ:OU6Ihb5iCvQC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-330-4285F4?logo=googlescholar&amp;labelColor=beige" alt="330 Google Scholar citations"> </a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">IEEE T-MM</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tmm18_disocclusion-480.webp 480w,/assets/img/publication_preview/tmm18_disocclusion-800.webp 800w,/assets/img/publication_preview/tmm18_disocclusion-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/tmm18_disocclusion.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tmm18_disocclusion.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:journals/tmm/CheungNS18" class="col-sm-8"> <div class="title">Spatio-Temporal Disocclusion Filling Using Novel Sprite Cells</div> <div class="author"> Chi Ho Cheung, <a href="https://www.ee.cuhk.edu.hk/~knngan/" rel="external nofollow noopener" target="_blank">King Ngi Ngan</a>, and <em>Lu Sheng</em> </div> <div class="periodical"> <em>IEEE Trans. Multim.</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> <a href="http://ieeexplore.ieee.org/document/8103880/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr18_off-480.webp 480w,/assets/img/publication_preview/cvpr18_off-800.webp 800w,/assets/img/publication_preview/cvpr18_off-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/cvpr18_off.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr18_off.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/cvpr/SunKSOZ18" class="col-sm-8"> <div class="title">Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition</div> <div class="author"> <a href="https://kevin-ssy.github.io/" rel="external nofollow noopener" target="_blank">Shuyang Sun</a>, Zhanghui Kuang, <em>Lu Sheng</em>, <a href="https://wlouyang.github.io/" rel="external nofollow noopener" target="_blank">Wanli Ouyang</a> , and Wei Zhang </div> <div class="periodical"> <em>In IEEE Conference on Computer Vision and Pattern Recognition</em> , 2018 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Sun_Optical_Flow_Guided_CVPR_2018_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/kevin-ssy/Optical-Flow-Guided-Feature" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=_8lB7xcAAAAJ&amp;citation_for_view=_8lB7xcAAAAJ:EUQCXRtRnyEC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-360-4285F4?logo=googlescholar&amp;labelColor=beige" alt="360 Google Scholar citations"> </a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr18_d2ae-480.webp 480w,/assets/img/publication_preview/cvpr18_d2ae-800.webp 800w,/assets/img/publication_preview/cvpr18_d2ae-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/cvpr18_d2ae.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr18_d2ae.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/cvpr/0015WSSYW18" class="col-sm-8"> <div class="title">Exploring Disentangled Feature Representation Beyond Face Identification</div> <div class="author"> Yu Liu, Fangyin Wei, <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a>, <em>Lu Sheng</em>, <a href="https://scholar.google.com/citations?user=rEYarG0AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Junjie Yan</a>, and <a href="https://www.ee.cuhk.edu.hk/~xgwang/" rel="external nofollow noopener" target="_blank">Xiaogang Wang</a> </div> <div class="periodical"> <em>In IEEE Conference on Computer Vision and Pattern Recognition</em> , 2018 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Liu_Exploring_Disentangled_Feature_CVPR_2018_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=_8lB7xcAAAAJ&amp;citation_for_view=_8lB7xcAAAAJ:abG-DnoFyZgC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-180-4285F4?logo=googlescholar&amp;labelColor=beige" alt="180 Google Scholar citations"> </a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr18_avatarnet-480.webp 480w,/assets/img/publication_preview/cvpr18_avatarnet-800.webp 800w,/assets/img/publication_preview/cvpr18_avatarnet-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/cvpr18_avatarnet.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr18_avatarnet.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/cvpr/ShengLSW18" class="col-sm-8"> <div class="title">Avatar-Net: Multi-Scale Zero-Shot Style Transfer by Feature Decoration</div> <div class="author"> <em>Lu Sheng</em>, Ziyi Lin, <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a>, and <a href="https://www.ee.cuhk.edu.hk/~xgwang/" rel="external nofollow noopener" target="_blank">Xiaogang Wang</a> </div> <div class="periodical"> <em>In IEEE Conference on Computer Vision and Pattern Recognition</em> , 2018 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/1805.03857" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/LucasSheng/avatar-net" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://lucassheng.github.io/avatar-net/" class="btn btn-sm z-depth-0" role="button">Website</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=_8lB7xcAAAAJ&amp;citation_for_view=_8lB7xcAAAAJ:b0M2c_1WBrUC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-330-4285F4?logo=googlescholar&amp;labelColor=beige" alt="330 Google Scholar citations"> </a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ECCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/eccv18_zoomnet-480.webp 480w,/assets/img/publication_preview/eccv18_zoomnet-800.webp 800w,/assets/img/publication_preview/eccv18_zoomnet-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/eccv18_zoomnet.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="eccv18_zoomnet.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/eccv/YinSLYWSL18" class="col-sm-8"> <div class="title">Zoom-Net: Mining Deep Feature Interactions for Visual Relationship Recognition</div> <div class="author"> Guojun Yin, <em>Lu Sheng</em> , Bin Liu , Nenghai Yu, <a href="https://www.ee.cuhk.edu.hk/~xgwang/" rel="external nofollow noopener" target="_blank">Xiaogang Wang</a>, <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a>, and <a href="https://www.mmlab-ntu.com/person/ccloy/" rel="external nofollow noopener" target="_blank">Chen Change Loy</a> </div> <div class="periodical"> <em>In European Conference on Computer Vision</em> , 2018 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Guojun_Yin_Zoom-Net_Mining_Deep_ECCV_2018_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=_8lB7xcAAAAJ&amp;citation_for_view=_8lB7xcAAAAJ:NhqRSupF_l8C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-160-4285F4?logo=googlescholar&amp;labelColor=beige" alt="160 Google Scholar citations"> </a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ACM MM</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/mm18_mlic-480.webp 480w,/assets/img/publication_preview/mm18_mlic-800.webp 800w,/assets/img/publication_preview/mm18_mlic-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/mm18_mlic.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mm18_mlic.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/mm/LiuSSYXP18" class="col-sm-8"> <div class="title">Multi-Label Image Classification via Knowledge Distillation from Weakly-Supervised Detection</div> <div class="author"> Yongcheng Liu, <em>Lu Sheng</em>, <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a>, <a href="https://scholar.google.com/citations?user=rEYarG0AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Junjie Yan</a>, Shiming Xiang, and Chunhong Pan </div> <div class="periodical"> <em>In ACM International Conference on Multimedia Conference</em> , 2018 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/1809.05884" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://dl.acm.org/doi/10.1145/3240508.3240567" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/Yochengliu/MLIC-KD-WSD" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://yochengliu.github.io/MLIC-KD-WSD/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=_8lB7xcAAAAJ&amp;citation_for_view=_8lB7xcAAAAJ:xtRiw3GOFMkC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-120-4285F4?logo=googlescholar&amp;labelColor=beige" alt="120 Google Scholar citations"> </a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr17_face-480.webp 480w,/assets/img/publication_preview/cvpr17_face-800.webp 800w,/assets/img/publication_preview/cvpr17_face-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/cvpr17_face.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr17_face.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/cvpr/ShengCCPN17" class="col-sm-8"> <div class="title">A Generative Model for Depth-Based Robust 3D Facial Pose Tracking</div> <div class="author"> <em>Lu Sheng</em>, Jianfei Cai, Tat-Jen Cham, Vladimir Pavlovic, and <a href="https://www.ee.cuhk.edu.hk/~knngan/" rel="external nofollow noopener" target="_blank">King Ngi Ngan</a> </div> <div class="periodical"> <em>In IEEE Conference on Computer Vision and Pattern Recognition</em> , 2017 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Sheng_A_Generative_Model_CVPR_2017_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ICCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/iccv17_hpnet-480.webp 480w,/assets/img/publication_preview/iccv17_hpnet-800.webp 800w,/assets/img/publication_preview/iccv17_hpnet-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/iccv17_hpnet.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="iccv17_hpnet.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/iccv/LiuZTSSYYW17" class="col-sm-8"> <div class="title">HydraPlus-Net: Attentive Deep Features for Pedestrian Analysis</div> <div class="author"> <a href="http://xh-liu.github.io/" rel="external nofollow noopener" target="_blank">Xihui Liu</a>, Haiyu Zhao, Maoqing Tian, <em>Lu Sheng</em>, <a href="https://amandajshao.github.io/" rel="external nofollow noopener" target="_blank">Jing Shao</a>, Shuai Yi, <a href="https://scholar.google.com/citations?user=rEYarG0AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Junjie Yan</a>, and <a href="https://www.ee.cuhk.edu.hk/~xgwang/" rel="external nofollow noopener" target="_blank">Xiaogang Wang</a> </div> <div class="periodical"> <em>In IEEE International Conference on Computer Vision</em> , 2017 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/1709.09930" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Liu_HydraPlus-Net_Attentive_Deep_ICCV_2017_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/xh-liu/HydraPlus-Net" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=_8lB7xcAAAAJ&amp;citation_for_view=_8lB7xcAAAAJ:dshw04ExmUIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-380-4285F4?logo=googlescholar&amp;labelColor=beige" alt="380 Google Scholar citations"> </a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" rel="external nofollow noopener" target="_blank">IEEE T-PAMI</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tpami16_face-480.webp 480w,/assets/img/publication_preview/tpami16_face-800.webp 800w,/assets/img/publication_preview/tpami16_face-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/tpami16_face.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tpami16_face.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:journals/pami/LiNPS16" class="col-sm-8"> <div class="title">Real-Time Head Pose Tracking with Online Face Template Reconstruction</div> <div class="author"> Songnan Li, <a href="https://www.ee.cuhk.edu.hk/~knngan/" rel="external nofollow noopener" target="_blank">King Ngi Ngan</a>, Raveendran Paramesran, and <em>Lu Sheng</em> </div> <div class="periodical"> <em>IEEE Trans. Pattern Anal. Mach. Intell.</em>, 2016 </div> <div class="periodical"> </div> <div class="links"> <a href="https://ieeexplore.ieee.org/document/7328312" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://www.ee.cuhk.edu.hk/%C2%A0knngan/2016/TPAMI_v38_n9_p1922-1928.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li></ol> <h2 class="bibliography">2015</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83" rel="external nofollow noopener" target="_blank">IEEE T-IP</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tip15_ss-480.webp 480w,/assets/img/publication_preview/tip15_ss-800.webp 800w,/assets/img/publication_preview/tip15_ss-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/tip15_ss.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tip15_ss.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:journals/tip/ShengNLL15" class="col-sm-8"> <div class="title">Online Temporally Consistent Indoor Depth Video Enhancement via Static Structure</div> <div class="author"> <em>Lu Sheng</em>, <a href="https://www.ee.cuhk.edu.hk/~knngan/" rel="external nofollow noopener" target="_blank">King Ngi Ngan</a>, Chern-Loon Lim, and Songnan Li </div> <div class="periodical"> <em>IEEE Trans. Image Process.</em>, 2015 </div> <div class="periodical"> </div> <div class="links"> <a href="https://ieeexplore.ieee.org/document/7067353" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ICME-W</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/icmew15_disc-480.webp 480w,/assets/img/publication_preview/icmew15_disc-800.webp 800w,/assets/img/publication_preview/icmew15_disc-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/icmew15_disc.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="icmew15_disc.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/icmcs/CheungSN15" class="col-sm-8"> <div class="title">A disocclusion filling method using multiple sprites with depth for virtual view synthesis</div> <div class="author"> Chi Ho Cheung, <em>Lu Sheng</em>, and <a href="https://www.ee.cuhk.edu.hk/~knngan/" rel="external nofollow noopener" target="_blank">King Ngi Ngan</a> </div> <div class="periodical"> <em>In IEEE International Conference on Multimedia &amp; Expo Workshops</em> , 2015 </div> <div class="periodical"> </div> <div class="links"> <a href="https://ieeexplore.ieee.org/document/7169773" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2014</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ACCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/accv14_wmf.webp-480.webp 480w,/assets/img/publication_preview/accv14_wmf.webp-800.webp 800w,/assets/img/publication_preview/accv14_wmf.webp-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/accv14_wmf.webp" class="preview z-depth-1 rounded" width="100%" height="auto" alt="accv14_wmf.webp" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/accv/ShengNH14" class="col-sm-8"> <div class="title">Accelerating the Distribution Estimation for the Weighted Median/Mode Filters</div> <div class="author"> <em>Lu Sheng</em>, <a href="https://www.ee.cuhk.edu.hk/~knngan/" rel="external nofollow noopener" target="_blank">King Ngi Ngan</a>, and Tak-Wai Hui </div> <div class="periodical"> <em>In Asian Conference on Computer Vision</em> , 2014 </div> <div class="periodical"> </div> <div class="links"> <a href="https://link.springer.com/chapter/10.1007/978-3-319-16817-3_1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ICIP</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/icip14_tss-480.webp 480w,/assets/img/publication_preview/icip14_tss-800.webp 800w,/assets/img/publication_preview/icip14_tss-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/icip14_tss.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="icip14_tss.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/icip/ShengNL14" class="col-sm-8"> <div class="title">Temporal depth video enhancement based on intrinsic static structure</div> <div class="author"> <em>Lu Sheng</em>, <a href="https://www.ee.cuhk.edu.hk/~knngan/" rel="external nofollow noopener" target="_blank">King Ngi Ngan</a>, and Songnan Li </div> <div class="periodical"> <em>In IEEE International Conference on Image Processing</em> , 2014 </div> <div class="periodical"> </div> <div class="links"> <a href="https://ieeexplore.ieee.org/abstract/document/7025585" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ICIP</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/icip14_calib-480.webp 480w,/assets/img/publication_preview/icip14_calib-800.webp 800w,/assets/img/publication_preview/icip14_calib-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/icip14_calib.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="icip14_calib.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/icip/LiNS14" class="col-sm-8"> <div class="title">Screen-camera calibration using a thread</div> <div class="author"> Songnan Li, <a href="https://www.ee.cuhk.edu.hk/~knngan/" rel="external nofollow noopener" target="_blank">King Ngi Ngan</a>, and <em>Lu Sheng</em> </div> <div class="periodical"> <em>In IEEE International Conference on Image Processing</em> , 2014 </div> <div class="periodical"> </div> <div class="links"> <a href="https://ieeexplore.ieee.org/abstract/document/7025698" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2013</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ICIP</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/icip13_holefilling-480.webp 480w,/assets/img/publication_preview/icip13_holefilling-800.webp 800w,/assets/img/publication_preview/icip13_holefilling-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/icip13_holefilling.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="icip13_holefilling.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/icip/ShengN13" class="col-sm-8"> <div class="title">Depth enhancement based on hybrid geometric hole filling strategy</div> <div class="author"> <em>Lu Sheng</em>, and <a href="https://www.ee.cuhk.edu.hk/~knngan/" rel="external nofollow noopener" target="_blank">King Ngi Ngan</a> </div> <div class="periodical"> <em>In IEEE International Conference on Image Processing</em> , 2013 </div> <div class="periodical"> </div> <div class="links"> <a href="https://ieeexplore.ieee.org/document/6738448/similar#similar" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100">ICVS</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/icvs13_face-480.webp 480w,/assets/img/publication_preview/icvs13_face-800.webp 800w,/assets/img/publication_preview/icvs13_face-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/icvs13_face.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="icvs13_face.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DBLP:conf/icvs/LiNS13" class="col-sm-8"> <div class="title">A Head Pose Tracking System Using RGB-D Camera</div> <div class="author"> Songnan Li, <a href="https://www.ee.cuhk.edu.hk/~knngan/" rel="external nofollow noopener" target="_blank">King Ngi Ngan</a>, and <em>Lu Sheng</em> </div> <div class="periodical"> <em>In International Conference on Computer Vision Systems</em> , 2013 </div> <div class="periodical"> </div> <div class="links"> <a href="https://link.springer.com/chapter/10.1007/978-3-642-39402-7_16" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Lu Sheng. Last updated: June 20, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>